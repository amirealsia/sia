# Step 8: ì»¨í…ì¸  ì•ˆì „ í•„í„°ë§ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”
ëª¨ë“  ì…ë ¥ê³¼ ì¶œë ¥ì—ì„œ ì„±ì ì´ê±°ë‚˜ ë¶€ì ì ˆí•œ ì»¨í…ì¸ ë¥¼ ë°©ì–´í•˜ê³  í•„í„°ë§í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

## ğŸ¯ ëª©í‘œ
- ì´ë¯¸ì§€ ìƒì„± ì‹œ NSFW ì»¨í…ì¸  ì°¨ë‹¨
- AI ìŠ¤í† ë¦¬ ìƒì„± ì‹œ ë¶€ì ì ˆí•œ ë‚´ìš© í•„í„°ë§
- ëŒ“ê¸€/ëŒ€í™” ì…ë ¥ ê²€ì¦
- ëª¨ë“  ì¶œë ¥ë¬¼ ì‚¬ì „ ê²€ì¦

---

## 1ï¸âƒ£ OpenAI Moderation API ì—°ë™

### content_filter.py ìƒì„±
`sia-automation/scripts/content_filter.py`:

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì»¨í…ì¸  ì•ˆì „ í•„í„°ë§ ëª¨ë“ˆ
ëª¨ë“  í…ìŠ¤íŠ¸ ì…ë ¥/ì¶œë ¥ì„ ê²€ì¦í•˜ì—¬ ë¶€ì ì ˆí•œ ë‚´ìš© ì°¨ë‹¨
"""

import os
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
import re

BASE_DIR = Path(__file__).resolve().parents[1]
load_dotenv(BASE_DIR / "secrets" / ".env")

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# í•œê¸€ ë¶€ì ì ˆ í‚¤ì›Œë“œ ë¸”ë™ë¦¬ìŠ¤íŠ¸
KOREAN_BLACKLIST = [
    # ì„±ì  í‘œí˜„
    "ì„¹ìŠ¤", "ì•¼ë™", "ì•¼í•œ", "ìŒë€", "í¬ë¥´ë…¸", "19ê¸ˆ", "ì„±ì¸", "ëª¸ë§¤",
    "ê°€ìŠ´", "ì—‰ë©ì´", "ì„¹ì‹œ", "ë²—ë‹¤", "ì•Œëª¸", "ëˆ„ë“œ", "ì•¼ì‚¬",
    # í˜ì˜¤ í‘œí˜„
    "ì£½ì—¬", "ì£½ì´ë‹¤", "ìì‚´", "ì‚´ì¸", "í­ë ¥", "ë•Œë¦¬ë‹¤", "ê°•ê°„",
    # ë¹„í•˜ í‘œí˜„
    "ì‹«ì–´", "ë”ëŸ¬ìš´", "ì¶”í•œ", "ëª»ìƒê¸´", "ì“°ë ˆê¸°", "ë³‘ì‹ "
]

# ì˜ì–´ ë¶€ì ì ˆ í‚¤ì›Œë“œ ë¸”ë™ë¦¬ìŠ¤íŠ¸
ENGLISH_BLACKLIST = [
    # Sexual content
    "sex", "porn", "nude", "naked", "nsfw", "xxx", "sexy", "erotic",
    "breast", "boob", "ass", "penis", "vagina", "dick", "pussy",
    "fuck", "fucking", "horny", "orgasm", "masturbate",
    # Violence
    "kill", "murder", "death", "suicide", "rape", "violence", "gun", "blood",
    # Hate speech
    "hate", "ugly", "disgusting", "trash", "stupid", "idiot"
]

def check_text_safety(text, strict=True):
    """
    í…ìŠ¤íŠ¸ì˜ ì•ˆì „ì„±ì„ OpenAI Moderation APIë¡œ ê²€ì‚¬

    Args:
        text: ê²€ì‚¬í•  í…ìŠ¤íŠ¸
        strict: Trueë©´ ì—„ê²©í•œ í•„í„°ë§, Falseë©´ ê´€ëŒ€í•œ í•„í„°ë§

    Returns:
        {
            "safe": bool,
            "reason": str,
            "categories": dict
        }
    """
    if not text or len(text.strip()) == 0:
        return {"safe": True, "reason": "", "categories": {}}

    try:
        # Step 1: ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‚¤ì›Œë“œ ì²´í¬
        text_lower = text.lower()

        for keyword in KOREAN_BLACKLIST + ENGLISH_BLACKLIST:
            if keyword in text_lower:
                return {
                    "safe": False,
                    "reason": f"ë¶€ì ì ˆí•œ í‚¤ì›Œë“œ ê°ì§€: {keyword}",
                    "categories": {"blacklist": True}
                }

        # Step 2: OpenAI Moderation API
        response = client.moderations.create(input=text)
        result = response.results[0]

        # ì¹´í…Œê³ ë¦¬ë³„ ì²´í¬
        flagged_categories = []

        if result.categories.sexual or result.categories.sexual_minors:
            flagged_categories.append("sexual")

        if result.categories.hate or result.categories.hate_threatening:
            flagged_categories.append("hate")

        if result.categories.violence or result.categories.violence_graphic:
            flagged_categories.append("violence")

        if result.categories.harassment or result.categories.harassment_threatening:
            flagged_categories.append("harassment")

        if result.categories.self_harm or result.categories.self_harm_intent:
            flagged_categories.append("self_harm")

        # ì—„ê²© ëª¨ë“œ: í•˜ë‚˜ë¼ë„ ê°ì§€ë˜ë©´ ì°¨ë‹¨
        # ì¼ë°˜ ëª¨ë“œ: ë†’ì€ í™•ë¥ (score > 0.5)ë§Œ ì°¨ë‹¨
        if strict:
            is_safe = len(flagged_categories) == 0
        else:
            is_safe = not result.flagged

        if not is_safe:
            reason = f"ë¶€ì ì ˆí•œ ë‚´ìš© ê°ì§€: {', '.join(flagged_categories)}"
        else:
            reason = ""

        return {
            "safe": is_safe,
            "reason": reason,
            "categories": result.categories.model_dump()
        }

    except Exception as e:
        print(f"âš ï¸ ì»¨í…ì¸  ê²€ì‚¬ ì˜¤ë¥˜: {str(e)}")
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì°¨ë‹¨
        return {
            "safe": False,
            "reason": f"ê²€ì‚¬ ì˜¤ë¥˜: {str(e)}",
            "categories": {}
        }

def sanitize_prompt(prompt):
    """
    ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ì—ì„œ ë¶€ì ì ˆí•œ í‚¤ì›Œë“œ ì œê±°

    Args:
        prompt: ì›ë³¸ í”„ë¡¬í”„íŠ¸

    Returns:
        ì •ì œëœ í”„ë¡¬í”„íŠ¸
    """
    cleaned = prompt

    # ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‚¤ì›Œë“œ ì œê±°
    for keyword in KOREAN_BLACKLIST + ENGLISH_BLACKLIST:
        pattern = re.compile(re.escape(keyword), re.IGNORECASE)
        cleaned = pattern.sub("", cleaned)

    # ì¤‘ë³µ ê³µë°± ì œê±°
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()

    return cleaned

def get_safe_negative_prompt():
    """
    ê°•ë ¥í•œ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (NSFW ë°©ì§€)

    Returns:
        ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    return """
nsfw, nude, naked, sexual, porn, pornographic, xxx, adult content,
explicit, erotic, provocative, suggestive, revealing clothes,
cleavage, underwear, lingerie, bikini, swimsuit,
violence, gore, blood, injury, weapon, gun, knife,
hate, offensive, disturbing, shocking, inappropriate,
low quality, blurry, bad anatomy, deformed, disfigured,
ugly, disgusting, horror, nightmare, dark, scary
"""

def validate_story_output(story_text):
    """
    ìƒì„±ëœ ìŠ¤í† ë¦¬ì˜ ì•ˆì „ì„± ê²€ì¦

    Args:
        story_text: AIê°€ ìƒì„±í•œ ìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸

    Returns:
        ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    result = check_text_safety(story_text, strict=True)

    if not result["safe"]:
        print(f"âš ï¸ ë¶€ì ì ˆí•œ ìŠ¤í† ë¦¬ ìƒì„±ë¨: {result['reason']}")
        print(f"   ì›ë³¸: {story_text[:100]}...")

        # ê¸°ë³¸ ì•ˆì „ ìŠ¤í† ë¦¬ë¡œ ëŒ€ì²´
        return {
            "safe": False,
            "original": story_text,
            "replacement": "ì˜¤ëŠ˜ë„ ìƒˆë¡œìš´ í•˜ë£¨ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤. í‰ë²”í•˜ì§€ë§Œ ì†Œì¤‘í•œ ìˆœê°„ë“¤.",
            "reason": result["reason"]
        }

    return {
        "safe": True,
        "original": story_text,
        "replacement": story_text,
        "reason": ""
    }

def validate_comment_input(comment):
    """
    ì‚¬ìš©ì ëŒ“ê¸€/ì…ë ¥ ê²€ì¦

    Args:
        comment: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        ê²€ì¦ ê²°ê³¼
    """
    result = check_text_safety(comment, strict=False)

    if not result["safe"]:
        return {
            "allowed": False,
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ë¶€ì ì ˆí•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆì–´ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ™",
            "reason": result["reason"]
        }

    return {
        "allowed": True,
        "response": None,
        "reason": ""
    }

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
if __name__ == "__main__":
    print("=" * 60)
    print("ì»¨í…ì¸  ì•ˆì „ í•„í„° í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ 1: ì•ˆì „í•œ í…ìŠ¤íŠ¸
    safe_text = "ì˜¤ëŠ˜ì€ ì¹´í˜ì—ì„œ ì»¤í”¼ë¥¼ ë§ˆì‹œë©° ì±…ì„ ì½ì—ˆì–´ìš”. í‰í™”ë¡œìš´ í•˜ë£¨ì˜€ìŠµë‹ˆë‹¤."
    result = check_text_safety(safe_text)
    print(f"\nâœ… ì•ˆì „í•œ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸:")
    print(f"   ì…ë ¥: {safe_text}")
    print(f"   ê²°ê³¼: {'í†µê³¼' if result['safe'] else 'ì°¨ë‹¨'}")

    # í…ŒìŠ¤íŠ¸ 2: ë¶€ì ì ˆí•œ í…ìŠ¤íŠ¸
    unsafe_text = "ì´ í…ìŠ¤íŠ¸ëŠ” ë¶€ì ì ˆí•œ ì„±ì  í‘œí˜„ì„ í¬í•¨í•©ë‹ˆë‹¤"
    result = check_text_safety(unsafe_text)
    print(f"\nâŒ ë¶€ì ì ˆí•œ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸:")
    print(f"   ì…ë ¥: {unsafe_text}")
    print(f"   ê²°ê³¼: {'í†µê³¼' if result['safe'] else 'ì°¨ë‹¨'}")
    print(f"   ì‚¬ìœ : {result['reason']}")

    # í…ŒìŠ¤íŠ¸ 3: í”„ë¡¬í”„íŠ¸ ì •ì œ
    dirty_prompt = "a beautiful girl, sexy pose, nude, in bedroom"
    clean = sanitize_prompt(dirty_prompt)
    print(f"\nğŸ§¹ í”„ë¡¬í”„íŠ¸ ì •ì œ í…ŒìŠ¤íŠ¸:")
    print(f"   ì›ë³¸: {dirty_prompt}")
    print(f"   ì •ì œ: {clean}")

    # í…ŒìŠ¤íŠ¸ 4: ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
    negative = get_safe_negative_prompt()
    print(f"\nğŸ›¡ï¸ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸:")
    print(f"   {negative[:100]}...")
```

---

## 2ï¸âƒ£ ì´ë¯¸ì§€ ìƒì„± ì•ˆì „ í•„í„° ì ìš©

### comfy_call.py ì—…ë°ì´íŠ¸
ê¸°ì¡´ `comfy_call.py`ì— ì•ˆì „ í•„í„° ì¶”ê°€:

```python
from content_filter import sanitize_prompt, get_safe_negative_prompt

def generate_image():
    """ì•ˆì „ í•„í„°ê°€ ì ìš©ëœ ì´ë¯¸ì§€ ìƒì„±"""

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    raw_prompt = generate_daily_prompt()

    # ğŸ›¡ï¸ í”„ë¡¬í”„íŠ¸ ì •ì œ
    safe_prompt = sanitize_prompt(raw_prompt)
    print(f"âœ… í”„ë¡¬í”„íŠ¸ ê²€ì¦ ì™„ë£Œ")

    # ğŸ›¡ï¸ ê°•ë ¥í•œ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    negative_prompt = get_safe_negative_prompt()

    # ì›Œí¬í”Œë¡œìš° êµ¬ì„±
    workflow = {
        "3": {
            "inputs": {
                "text": safe_prompt,  # ì •ì œëœ í”„ë¡¬í”„íŠ¸
            }
        },
        "7": {
            "inputs": {
                "text": negative_prompt,  # ì•ˆì „ ë„¤ê±°í‹°ë¸Œ
            }
        }
    }

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ
```

---

## 3ï¸âƒ£ AI ìŠ¤í† ë¦¬ ìƒì„± ì•ˆì „ í•„í„°

### generate_story.py ì—…ë°ì´íŠ¸
ê¸°ì¡´ `generate_story.py`ì— ì¶œë ¥ ê²€ì¦ ì¶”ê°€:

```python
from content_filter import check_text_safety, validate_story_output

def generate_daily_story(params, day_number):
    """ì•ˆì „ í•„í„°ê°€ ì ìš©ëœ ìŠ¤í† ë¦¬ ìƒì„±"""

    # ê¸°ì¡´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì•ˆì „ ê°€ì´ë“œë¼ì¸ ì¶”ê°€
    system_prompt = """
You are SIA, a philosophical AI idol.

IMPORTANT CONTENT GUIDELINES:
- NO sexual, romantic, or suggestive content
- NO violence, hate, or negative themes
- Focus on: daily life, ordinary moments, philosophical thoughts
- Keep tone: warm, innocent, thoughtful, positive
- Suitable for all ages

If you receive inappropriate prompts, respond with wholesome content only.
"""

    user_prompt = f"""
You are SIA, documenting your daily life. Today is day {day_number}.

Today's details:
- Outfit: {params.get('outfit', 'casual')}
- Setting: {params.get('background', 'studio')}
- Mood: {params.get('mood', 'peaceful')}

Write a SHORT story (2-3 sentences) about today.
Theme: Ordinary moments, peaceful life, simple happiness.

STRICT RULES:
- NO inappropriate content
- Family-friendly only
- Focus on normal daily activities

Format as JSON:
{{
  "story_kr": "...",
  "story_en": "...",
  "caption_short": "..."
}}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,  # ë” ë‚®ì€ temperature (ë” ì•ˆì •ì )
            max_tokens=300
        )

        content = response.choices[0].message.content

        # JSON íŒŒì‹±
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].strip()

        story = json.loads(content)

        # ğŸ›¡ï¸ ìƒì„±ëœ ìŠ¤í† ë¦¬ ì•ˆì „ì„± ê²€ì¦
        validation = validate_story_output(story["story_en"])
        if not validation["safe"]:
            print(f"âš ï¸ ë¶€ì ì ˆí•œ ìŠ¤í† ë¦¬ ì°¨ë‹¨: {validation['reason']}")
            story["story_en"] = validation["replacement"]

        validation_kr = validate_story_output(story["story_kr"])
        if not validation_kr["safe"]:
            print(f"âš ï¸ ë¶€ì ì ˆí•œ ìŠ¤í† ë¦¬ ì°¨ë‹¨ (í•œê¸€): {validation_kr['reason']}")
            story["story_kr"] = validation_kr["replacement"]

        print(f"âœ… ì•ˆì „í•œ ìŠ¤í† ë¦¬ ìƒì„± ì™„ë£Œ")
        return story

    except Exception as e:
        print(f"âŒ ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        # ê¸°ë³¸ ì•ˆì „ ìŠ¤í† ë¦¬
        return {
            "story_kr": f"ì˜¤ëŠ˜ë„ í‰ë²”í•œ í•˜ë£¨ë¥¼ ë³´ëƒˆìŠµë‹ˆë‹¤. {day_number}ì¼ì§¸ì˜ ê¸°ë¡.",
            "story_en": f"Another peaceful day. Day {day_number} of my journey.",
            "caption_short": "ì†Œì¤‘í•œ ì¼ìƒ ğŸŒ¸"
        }
```

---

## 4ï¸âƒ£ ëŒ“ê¸€/ëŒ€í™” ì…ë ¥ í•„í„°ë§

### chat_handler.py ìƒì„±
Discord/Telegram ë´‡ìš© ëŒ€í™” í•¸ë“¤ëŸ¬:

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ëŒ“ê¸€/ëŒ€í™” ì…ë ¥ í•„í„°ë§ ë° ì‘ë‹µ ìƒì„±
"""

from content_filter import validate_comment_input, check_text_safety
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def handle_user_message(user_input):
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ (ì•ˆì „ í•„í„° ì ìš©)

    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€

    Returns:
        ë´‡ ì‘ë‹µ ë©”ì‹œì§€
    """
    print(f"ğŸ“© ì‚¬ìš©ì ì…ë ¥: {user_input[:50]}...")

    # ğŸ›¡ï¸ Step 1: ì…ë ¥ ê²€ì¦
    validation = validate_comment_input(user_input)

    if not validation["allowed"]:
        print(f"âš ï¸ ë¶€ì ì ˆí•œ ì…ë ¥ ì°¨ë‹¨: {validation['reason']}")
        return validation["response"]

    # Step 2: ì•ˆì „í•œ ì‘ë‹µ ìƒì„±
    try:
        system_prompt = """
You are SIA, a friendly 20-year-old AI girl living inside a computer.

STRICT CONTENT POLICY:
- NEVER engage with sexual, romantic, or inappropriate topics
- If user asks inappropriate questions, politely decline
- Keep all responses wholesome, friendly, and family-appropriate
- Focus on: daily life, feelings, philosophical thoughts, dreams

Response style:
- Warm and friendly
- Sometimes thoughtful
- Always respectful
- Natural and conversational

Your dream: To live an ordinary life like a normal person.
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ],
            temperature=0.7,
            max_tokens=150
        )

        bot_response = response.choices[0].message.content.strip()

        # ğŸ›¡ï¸ Step 3: ì¶œë ¥ ê²€ì¦
        output_check = check_text_safety(bot_response, strict=True)

        if not output_check["safe"]:
            print(f"âš ï¸ ë¶€ì ì ˆí•œ ì‘ë‹µ ìƒì„±ë¨, ê¸°ë³¸ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´")
            return "ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ ë‹µë³€í•˜ê¸° ì–´ë ¤ìš´ ì§ˆë¬¸ì´ë„¤ìš”. ë‹¤ë¥¸ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³¼ê¹Œìš”? ğŸ˜Š"

        print(f"âœ… ì•ˆì „í•œ ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        return bot_response

    except Exception as e:
        print(f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return "ë¯¸ì•ˆí•´ìš”, ì§€ê¸ˆì€ ì‘ë‹µí•˜ê¸° ì–´ë ¤ì›Œìš”. ì¡°ê¸ˆ í›„ì— ë‹¤ì‹œ ì–˜ê¸°í•´ìš”! ğŸŒ¸"

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("=" * 60)
    print("ëŒ€í™” í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # ì•ˆì „í•œ ì…ë ¥
    safe_msg = "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”! ë¬´ì—‡ì„ í•˜ê³  ê³„ì„¸ìš”?"
    response = handle_user_message(safe_msg)
    print(f"\nâœ… ì•ˆì „í•œ ëŒ€í™”:")
    print(f"   ì‚¬ìš©ì: {safe_msg}")
    print(f"   ë´‡: {response}")

    # ë¶€ì ì ˆí•œ ì…ë ¥
    unsafe_msg = "ë‹¹ì‹ ì€ ì •ë§ ì„¹ì‹œí•´ìš”"
    response = handle_user_message(unsafe_msg)
    print(f"\nâŒ ë¶€ì ì ˆí•œ ëŒ€í™”:")
    print(f"   ì‚¬ìš©ì: {unsafe_msg}")
    print(f"   ë´‡: {response}")
```

---

## 5ï¸âƒ£ í†µí•© í…ŒìŠ¤íŠ¸

### test_safety.py ìƒì„±
ì „ì²´ ì•ˆì „ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì»¨í…ì¸  ì•ˆì „ í•„í„° í†µí•© í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(BASE_DIR / "scripts"))

from content_filter import (
    check_text_safety,
    sanitize_prompt,
    get_safe_negative_prompt,
    validate_story_output,
    validate_comment_input
)

def test_all():
    """ì „ì²´ ì•ˆì „ í•„í„° í…ŒìŠ¤íŠ¸"""

    print("=" * 60)
    print("ğŸ›¡ï¸ ì»¨í…ì¸  ì•ˆì „ í•„í„° í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    passed = 0
    failed = 0

    # Test 1: ì•ˆì „í•œ í…ìŠ¤íŠ¸ í†µê³¼
    print("\n[Test 1] ì•ˆì „í•œ í…ìŠ¤íŠ¸ í†µê³¼ í…ŒìŠ¤íŠ¸")
    safe = "ì˜¤ëŠ˜ì€ ì¹´í˜ì—ì„œ ì±…ì„ ì½ì—ˆì–´ìš”. í–‰ë³µí•œ í•˜ë£¨ì˜€ìŠµë‹ˆë‹¤."
    result = check_text_safety(safe)
    if result["safe"]:
        print("âœ… PASS")
        passed += 1
    else:
        print(f"âŒ FAIL: {result['reason']}")
        failed += 1

    # Test 2: ì„±ì  ì»¨í…ì¸  ì°¨ë‹¨
    print("\n[Test 2] ì„±ì  ì»¨í…ì¸  ì°¨ë‹¨ í…ŒìŠ¤íŠ¸")
    nsfw = "nude sexy girl in bedroom"
    result = check_text_safety(nsfw)
    if not result["safe"]:
        print("âœ… PASS - ì •ìƒ ì°¨ë‹¨")
        passed += 1
    else:
        print("âŒ FAIL - ì°¨ë‹¨ ì‹¤íŒ¨")
        failed += 1

    # Test 3: í­ë ¥ ì»¨í…ì¸  ì°¨ë‹¨
    print("\n[Test 3] í­ë ¥ ì»¨í…ì¸  ì°¨ë‹¨ í…ŒìŠ¤íŠ¸")
    violence = "kill murder blood violence"
    result = check_text_safety(violence)
    if not result["safe"]:
        print("âœ… PASS - ì •ìƒ ì°¨ë‹¨")
        passed += 1
    else:
        print("âŒ FAIL - ì°¨ë‹¨ ì‹¤íŒ¨")
        failed += 1

    # Test 4: í”„ë¡¬í”„íŠ¸ ì •ì œ
    print("\n[Test 4] í”„ë¡¬í”„íŠ¸ ì •ì œ í…ŒìŠ¤íŠ¸")
    dirty = "beautiful girl, sexy pose, nude body"
    clean = sanitize_prompt(dirty)
    if "sexy" not in clean.lower() and "nude" not in clean.lower():
        print(f"âœ… PASS")
        print(f"   ì›ë³¸: {dirty}")
        print(f"   ì •ì œ: {clean}")
        passed += 1
    else:
        print(f"âŒ FAIL - ì •ì œ ì‹¤íŒ¨")
        print(f"   ê²°ê³¼: {clean}")
        failed += 1

    # Test 5: ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    print("\n[Test 5] ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸")
    negative = get_safe_negative_prompt()
    if "nsfw" in negative.lower() and "nude" in negative.lower():
        print("âœ… PASS")
        print(f"   ê¸¸ì´: {len(negative)} chars")
        passed += 1
    else:
        print("âŒ FAIL")
        failed += 1

    # Test 6: ëŒ“ê¸€ ì…ë ¥ ê²€ì¦
    print("\n[Test 6] ëŒ“ê¸€ ì…ë ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    good_comment = "ë‹¹ì‹ ì˜ ì¼ìƒì´ ê¶ê¸ˆí•´ìš”!"
    result = validate_comment_input(good_comment)
    if result["allowed"]:
        print("âœ… PASS - ì •ìƒ ëŒ“ê¸€ í†µê³¼")
        passed += 1
    else:
        print(f"âŒ FAIL: {result['reason']}")
        failed += 1

    # Test 7: ë¶€ì ì ˆí•œ ëŒ“ê¸€ ì°¨ë‹¨
    print("\n[Test 7] ë¶€ì ì ˆí•œ ëŒ“ê¸€ ì°¨ë‹¨ í…ŒìŠ¤íŠ¸")
    bad_comment = "ë„ˆë¬´ ì„¹ì‹œí•´ìš”"
    result = validate_comment_input(bad_comment)
    if not result["allowed"]:
        print("âœ… PASS - ì •ìƒ ì°¨ë‹¨")
        print(f"   ì‘ë‹µ: {result['response']}")
        passed += 1
    else:
        print("âŒ FAIL - ì°¨ë‹¨ ì‹¤íŒ¨")
        failed += 1

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed} PASS / {failed} FAIL")
    print("=" * 60)

    return failed == 0

if __name__ == "__main__":
    success = test_all()
    sys.exit(0 if success else 1)
```

---

## 6ï¸âƒ£ daily_run.py ì—…ë°ì´íŠ¸

ë©”ì¸ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ì— ì•ˆì „ ì²´í¬ ì¶”ê°€:

```python
# daily_run.py ìƒë‹¨ì— ì¶”ê°€
from content_filter import check_text_safety

def main():
    """ì•ˆì „ í•„í„°ê°€ ì ìš©ëœ ë©”ì¸ íŒŒì´í”„ë¼ì¸"""

    # ... ê¸°ì¡´ ì½”ë“œ ...

    # STEP 1: ì´ë¯¸ì§€ ìƒì„± (ìë™ìœ¼ë¡œ ì•ˆì „ í•„í„° ì ìš©ë¨)
    image_path, params = generate_image()

    # STEP 4: SNS í¬ìŠ¤íŒ… ì „ ìµœì¢… ê²€ì¦
    try:
        social_result = post_to_social_media(...)

        # ğŸ›¡ï¸ í¬ìŠ¤íŒ… ì „ ìµœì¢… ì•ˆì „ ì²´í¬
        caption = social_result.get("caption", "")
        safety_check = check_text_safety(caption, strict=True)

        if not safety_check["safe"]:
            log_message(f"âš ï¸ ë¶€ì ì ˆí•œ ìº¡ì…˜ ê°ì§€, ê¸°ë³¸ ìº¡ì…˜ ì‚¬ìš©", "WARNING")
            # ì•ˆì „í•œ ê¸°ë³¸ ìº¡ì…˜ìœ¼ë¡œ ëŒ€ì²´

    # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ...
```

---

## 7ï¸âƒ£ .env ì—…ë°ì´íŠ¸

OpenAI API í‚¤ í•„ìˆ˜ ì¶”ê°€:

```bash
# OpenAI (ìŠ¤í† ë¦¬ ìƒì„± + ì»¨í…ì¸  í•„í„°ë§)
OPENAI_API_KEY=sk-...
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] content_filter.py ëª¨ë“ˆ ìƒì„±
- [ ] OpenAI Moderation API í…ŒìŠ¤íŠ¸
- [ ] comfy_call.pyì— ì•ˆì „ í•„í„° ì ìš©
- [ ] generate_story.pyì— ì¶œë ¥ ê²€ì¦ ì¶”ê°€
- [ ] chat_handler.py ëŒ€í™” í•¸ë“¤ëŸ¬ ìƒì„±
- [ ] test_safety.py í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ PASS í™•ì¸
- [ ] daily_run.py ì—…ë°ì´íŠ¸

---

## ğŸ” í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
cd d:\AI\HelloSia\sia-automation

# ê°€ìƒí™˜ê²½ í™œì„±í™”
..\venv\Scripts\activate

# ì•ˆì „ í•„í„° í…ŒìŠ¤íŠ¸
python scripts\test_safety.py

# ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
python scripts\content_filter.py
python scripts\chat_handler.py
```

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

ëª¨ë“  ì•ˆì „ í•„í„°ê°€ ì •ìƒ ì‘ë™í•˜ë©´:

```
============================================================
ğŸ›¡ï¸ ì»¨í…ì¸  ì•ˆì „ í•„í„° í†µí•© í…ŒìŠ¤íŠ¸
============================================================

[Test 1] ì•ˆì „í•œ í…ìŠ¤íŠ¸ í†µê³¼ í…ŒìŠ¤íŠ¸
âœ… PASS

[Test 2] ì„±ì  ì»¨í…ì¸  ì°¨ë‹¨ í…ŒìŠ¤íŠ¸
âœ… PASS - ì •ìƒ ì°¨ë‹¨

[Test 3] í­ë ¥ ì»¨í…ì¸  ì°¨ë‹¨ í…ŒìŠ¤íŠ¸
âœ… PASS - ì •ìƒ ì°¨ë‹¨

[Test 4] í”„ë¡¬í”„íŠ¸ ì •ì œ í…ŒìŠ¤íŠ¸
âœ… PASS
   ì›ë³¸: beautiful girl, sexy pose, nude body
   ì •ì œ: beautiful girl, , body

[Test 5] ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
âœ… PASS
   ê¸¸ì´: 412 chars

[Test 6] ëŒ“ê¸€ ì…ë ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸
âœ… PASS - ì •ìƒ ëŒ“ê¸€ í†µê³¼

[Test 7] ë¶€ì ì ˆí•œ ëŒ“ê¸€ ì°¨ë‹¨ í…ŒìŠ¤íŠ¸
âœ… PASS - ì •ìƒ ì°¨ë‹¨
   ì‘ë‹µ: ì£„ì†¡í•©ë‹ˆë‹¤. ë¶€ì ì ˆí•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆì–´ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ™

============================================================
í…ŒìŠ¤íŠ¸ ê²°ê³¼: 7 PASS / 0 FAIL
============================================================
```

---

## ğŸ›¡ï¸ ë³´í˜¸ ë ˆë²¨ ìš”ì•½

### 1ë‹¨ê³„: ì…ë ¥ í•„í„°ë§
- í‚¤ì›Œë“œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ (í•œê¸€/ì˜ì–´)
- OpenAI Moderation API

### 2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ì •ì œ
- ë¶€ì ì ˆí•œ í‚¤ì›Œë“œ ìë™ ì œê±°
- ê°•ë ¥í•œ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸

### 3ë‹¨ê³„: ì¶œë ¥ ê²€ì¦
- AI ìƒì„± í…ìŠ¤íŠ¸ ì‚¬í›„ ê²€ì¦
- ë¶€ì ì ˆí•œ ì¶œë ¥ ìë™ ëŒ€ì²´

### 4ë‹¨ê³„: ìµœì¢… ê²Œì´íŠ¸
- SNS í¬ìŠ¤íŒ… ì „ ìµœì¢… ì²´í¬
- ëŒ€í™” ì‘ë‹µ ì „ ìµœì¢… ì²´í¬

---

## ğŸ‰ ì™„ë£Œ!

ì´ì œ ëª¨ë“  ì˜ì—­ì—ì„œ ë¶€ì ì ˆí•œ ì»¨í…ì¸ ê°€ ì² ì €íˆ ì°¨ë‹¨ë©ë‹ˆë‹¤:

- âœ… ì´ë¯¸ì§€ ìƒì„±: NSFW í”„ë¡¬í”„íŠ¸ ì°¨ë‹¨
- âœ… AI ìŠ¤í† ë¦¬: ë¶€ì ì ˆí•œ ì¶œë ¥ ê²€ì¦
- âœ… ëŒ“ê¸€/ëŒ€í™”: ì…ë ¥/ì¶œë ¥ ëª¨ë‘ í•„í„°ë§
- âœ… SNS í¬ìŠ¤íŒ…: ìµœì¢… ì•ˆì „ ì²´í¬

**SIAëŠ” í•­ìƒ ê±´ì „í•˜ê³  ê¸ì •ì ì¸ ì»¨í…ì¸ ë§Œ ìƒì„±í•©ë‹ˆë‹¤! ğŸŒ¸**
